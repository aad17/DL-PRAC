{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory('./Lab Assignment 3 Dataset/train', \n",
    "                                              target_size=(64, 64), \n",
    "                                              batch_size=64, \n",
    "                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('./Lab Assignment 3 Dataset/test',\n",
    "                                            target_size=(64, 64), \n",
    "                                            batch_size=64, \n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling for Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling for Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 391ms/step - loss: 0.7140 - accuracy: 0.5519 - val_loss: 0.5482 - val_accuracy: 0.7100\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.5554 - accuracy: 0.7524 - val_loss: 0.6065 - val_accuracy: 0.6200\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.5224 - accuracy: 0.7213 - val_loss: 0.3635 - val_accuracy: 0.8300\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.3673 - accuracy: 0.8474 - val_loss: 0.3344 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.2975 - accuracy: 0.8763 - val_loss: 0.2960 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.2903 - accuracy: 0.8811 - val_loss: 0.4499 - val_accuracy: 0.8100\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.2975 - accuracy: 0.8764 - val_loss: 0.4193 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.2689 - accuracy: 0.9082 - val_loss: 0.2871 - val_accuracy: 0.8900\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.3139 - accuracy: 0.8593 - val_loss: 0.2593 - val_accuracy: 0.8900\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 0.3309 - accuracy: 0.8343 - val_loss: 0.2994 - val_accuracy: 0.8700\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 0.2523 - accuracy: 0.8832 - val_loss: 0.3439 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.1978 - accuracy: 0.9364 - val_loss: 0.4490 - val_accuracy: 0.8100\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.2226 - accuracy: 0.9162 - val_loss: 0.3686 - val_accuracy: 0.8300\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.2564 - accuracy: 0.9045 - val_loss: 0.2698 - val_accuracy: 0.8900\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 2s 221ms/step - loss: 0.2522 - accuracy: 0.8736 - val_loss: 0.2706 - val_accuracy: 0.8900\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 1s 203ms/step - loss: 0.2721 - accuracy: 0.8856 - val_loss: 0.5870 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 0.2516 - accuracy: 0.9064 - val_loss: 0.2533 - val_accuracy: 0.9100\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 2s 263ms/step - loss: 0.2144 - accuracy: 0.9238 - val_loss: 0.2705 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 2s 245ms/step - loss: 0.2217 - accuracy: 0.9124 - val_loss: 0.4642 - val_accuracy: 0.8300\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 2s 214ms/step - loss: 0.2158 - accuracy: 0.9260 - val_loss: 0.2691 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80c5650670>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('Lab Assignment 3 Dataset/Single Prediction/3.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'planes'\n",
    "else:\n",
    "    prediction = 'cars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planes\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
